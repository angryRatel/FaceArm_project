# 🤖 Auto Weld: AI 기반 협동 로봇 작업 어시스턴트
작업자의 음성 명령을 인식해 물체를 전달하고 사람의 위치를 인지해 동작하는, ROS2 기반의 AI 협동 로봇 작업 어시스턴트를 개발한 프로젝트입니다
## 1. 📊 개발 과정
- 프로젝트명: **Auto Weld**
- 기간: 2024.05.23 ~ 2024.06.05 (총 2주)
- 팀명: 가디구디 (TEAM B-3조)
- 개발 배경: 고령화 사회에 대응한 **서비스 협동 로봇 구현**을 목표로 진행됨
- 개발 흐름:
  - 주제 선정 및 자료 조사
  - 파트별 기능 구현 및 테스트
  - 전체 통합 및 오류 수정
  - 최종 테스트 및 발표 자료 제작

## 2. 🛠️ 주요 기능 구현 과정
- **object_detection.py**: YOLO + Realsense로 객체 위치 인식
- **face_yolo.py**: 사용자 얼굴 인식 및 World 좌표 리매핑
- **get_keyword.py**: 음성 명령어에서 키워드 추출 (예: "OOO 갖다 줘")
- **robot_control.py**: 명령어에 따라 로봇 이동/그리퍼 작동

## 3. 💡 도전 과제와 문제 해결 방법
- **도전**: 공공 데이터셋만으로는 객체 인식 정확도 미흡
- **해결**: 직접 데이터 수집 및 라벨링 → 정확도 개선
- **도전**: 좌표 리매핑 오차
- **해결**: 카메라/World 좌표 정규화 로직 개발

## 4. 👥 협업 내용 (맡은 역할), 진행 과정
| 이름 | 역할 |
|------|------|
| 최정호 | 객체 인식 모델 학습, 발표 |
| 이하빈 | 로봇 동작 구현, 프롬프트 코드 |
| 이세현 | 예외처리 코드 작성 |
| 홍진규 | 얼굴 인식 모델 학습, 좌표 변환 |

## 5. 🎯 성과 및 결과물
- 시연 영상: [YouTube](https://youtu.be/wykA4MYREYk)
- 객체/얼굴 인식 + 음성 명령 기반 작업 보조 로봇 구현
- 실시간 명령 인식 및 물체 전달, 복귀, 위치 이동 가능

## 6. 📈 프로젝트 결과 (목표와 성과)
- **목표**: 작업 보조 로봇 개발 (비접촉, 음성 기반)
- **성과**: 5종 음성 명령어 처리, 다중 센서 통합, 외력 감지 제어 등 구현 성공
- 예외 처리 및 사용자 다중 감지 조건 추가

## 7. 📸 프로젝트 화면 및 기능 데모
- 물체 인식 화면 (YOLO + Depth)
- 얼굴 인식 및 이동 위치 리매핑 결과
- 로봇 이동 및 그리퍼 작동 시나리오 스냅샷
- [GitHub 링크](https://github.com/ROKEY-SPARK/DoosanBootcamp.git)

## 8. ✍️ 후기 및 향후 개선 사항
- 음성 인식 속도 개선 필요
- 사투리 및 발음 차이에 따른 인식 오류 개선 필요
- 실사용 환경에서의 테스트가 아직 부족

## 9. 🎓 개인적 성찰 및 배운 점
- ROS2 기반 로봇 제어 시스템 구조 이해
- 데이터셋 설계와 학습 모델 성능 개선 경험
- 예외 처리와 사용자 인터랙션 설계의 중요성 체득

## 10. 🚀 개선 및 확장 아이디어
- 다중 사용자 동시 인식 기능 추가
- 웹 기반 원격 제어 UI 개발
- 시니어 복지 시스템 연동 및 서비스 실증화 시도

---

본 프로젝트는 K-Digital Training 프로그램의 일환으로 진행되었습니다.
"""

portfolio_readme_path = "/mnt/data/README_portfolio_format.md"
with open(portfolio_readme_path, "w", encoding="utf-8") as f:
    f.write(portfolio_formatted_content)

portfolio_readme_path
